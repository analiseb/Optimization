{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Constrained optimization, equality constraints\n",
    "\n",
    "### Analise Burko & Marcos de la Torre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the Sequential Quadratic Optimization method to the problem:\n",
    "\n",
    "$$ minimize:\\   f(x_1, x_2) = e^{3x_1} + e^{−4x_2}$$\n",
    "\n",
    "$$ subject\\  to:\\  h(x_1, x_2) = x_1^2 + x_2^2 − 1 = 0 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_f(x):\n",
    "    '''Function to optimize'''\n",
    "    x1, x2 = x\n",
    "    return np.exp(3*x1) + np.exp(-4*x2)\n",
    "\n",
    "def grad_f(x):\n",
    "    '''Gradient of the function at the given point'''\n",
    "    x1, x2 = x\n",
    "    return np.array([3*np.exp(3*x1), -4*np.exp(-4*x2)], dtype=float)\n",
    "\n",
    "def hessian_f(x):\n",
    "    '''Hessian of the function at the given point'''\n",
    "    x1, x2 = x\n",
    "    return np.array([[9*np.exp(3*x1), 0], [0, 16*np.exp(-4*x2)]], dtype=float)\n",
    "    \n",
    "def func_h(x):\n",
    "    '''Function of the equality constraint'''\n",
    "    x1, x2 = x\n",
    "    return x1**2 + x2**2 -1\n",
    "\n",
    "def grad_h(x):\n",
    "    '''Gradient of the equality constraint'''\n",
    "    x1, x2 = x\n",
    "    return np.array([2*x1, 2*x2], dtype=float)\n",
    "\n",
    "def hessian_h(x):\n",
    "    '''Hessian of the equality constraint'''\n",
    "    return np.array([[2, 0], [0, 2]], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [-1.  1.] lambda= -1\n",
      "grad x_0:\n",
      "[ 0.14936121 -0.07326256]\n",
      "hessian x_0:\n",
      "[[0.44808362 0.        ]\n",
      " [0.         0.29305022]]\n"
     ]
    }
   ],
   "source": [
    "# Check that the values of step 0 are as expected\n",
    "x = np.array([-1, 1], dtype=float)\n",
    "lam = -1\n",
    "print('Initial values: x=', x, 'lambda=', lam)\n",
    "print('grad x_0:')\n",
    "print(grad_f(x))\n",
    "print('hessian x_0:')\n",
    "print(hessian_f(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Running algorithm with constant alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_quadratic(x_initial, lam_initial, convergence_criterion = 10e-3, print_steps=False):\n",
    "    # Initial values\n",
    "    x = np.array(x_initial, dtype=float)\n",
    "    lam = lam_initial\n",
    "    print('Initial values: x=', x, 'lambda=', lam)\n",
    "\n",
    "    for i in range(100):  # Maximum number of iterations\n",
    "        gr_f = np.expand_dims(grad_f(x), axis=1)  # Gradient of f as column vector\n",
    "        gr_h = np.expand_dims(grad_h(x), axis=1)  # Gradient of h as column vector\n",
    "        \n",
    "        if np.linalg.norm(gr_f - lam*gr_h) < convergence_criterion:\n",
    "            print('Convergence reached at step', str(i-1))\n",
    "            print('Final value: x=', x, 'lambda=', lam)\n",
    "            break\n",
    "\n",
    "        # Create composite matrix A and vector b to solve the quadratic problem.\n",
    "        grad_lagrange = gr_f - lam*gr_h\n",
    "        hessian_lagrange = hessian_f(x) - lam*hessian_h(x)\n",
    "        A = np.concatenate((np.concatenate((hessian_lagrange, -gr_h), axis=1),\n",
    "                            np.concatenate((-gr_h.T, np.array([[0]])), axis=1)),\n",
    "                           axis=0)\n",
    "        b = np.concatenate((-grad_lagrange, np.array([[func_h(x)]], dtype=float)), axis=0)\n",
    "        \n",
    "        # If matrix A is singular, a different starting point is required.\n",
    "        if np.linalg.cond(A) >= 1/sys.float_info.epsilon:\n",
    "            print('The algorithm does not work with this starting point because the resulting matrix is '\n",
    "                             'singular or ill-conditioned. Please try with a different starting point.')  \n",
    "            return None\n",
    "        # Obtain descent direction.\n",
    "        direc = np.linalg.solve(A, b)\n",
    "        # Update estimations\n",
    "        x[0] = x[0] + direc[0,0]\n",
    "        x[1] = x[1] + direc[1,0]\n",
    "        lam = lam + direc[2,0]\n",
    "        if print_steps:\n",
    "            print('Step', str(i), '- descent direction', direc)\n",
    "            print('Step', str(i), '- new estimates x=', x, ', lambda=', lam)\n",
    "    \n",
    "    return x, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [-1.  1.] lambda= -1\n",
      "Convergence reached at step 2\n",
      "Final value: x= [-0.74833818  0.66332345] lambda= -0.21232390186241443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.74833818,  0.66332345]), -0.21232390186241443)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=[-1,1], lam_initial=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Starting at (-1,1) and lambda=-1, the algorithm converges very fast into the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.1: Trying with other starting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [0.  0.1] lambda= 0\n",
      "Convergence reached at step 9\n",
      "Final value: x= [-0.74839471  0.6632797 ] lambda= -0.2122817677373336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.74839471,  0.6632797 ]), -0.2122817677373336)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=[0,0.1], lam_initial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [1. 1.] lambda= 0\n",
      "Convergence reached at step 6\n",
      "Final value: x= [-0.74664493  0.66790451] lambda= -0.20772098461707672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.74664493,  0.66790451]), -0.20772098461707672)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=[1,1], lam_initial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [4. 5.] lambda= 0\n",
      "Convergence reached at step 14\n",
      "Final value: x= [-0.74762403  0.664646  ] lambda= -0.21093137089499014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.74762403,  0.664646  ]), -0.21093137089499014)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=[4,5], lam_initial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [-5. -6.] lambda= 5\n",
      "Convergence reached at step 24\n",
      "Final value: x= [-0.74849052  0.66320119] lambda= -0.2121705340309161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.74849052,  0.66320119]), -0.2121705340309161)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=[-5,-6], lam_initial=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.2: Testing distant points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [10. 10.] lambda= 0\n",
      "The algorithm does not work with this starting point because the resulting matrix is singular or ill-conditioned. Please try with a different starting point.\n"
     ]
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=[10,10], lam_initial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [-10. -10.] lambda= 0\n",
      "The algorithm does not work with this starting point because the resulting matrix is singular or ill-conditioned. Please try with a different starting point.\n"
     ]
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=[-10,-10], lam_initial=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of experiments:**\n",
    "\n",
    "- With values of x of 0,0 and around, the algorithm **converges** very fast.\n",
    "- With values of x of (5,5) and (-5,,-5), the algorithm still **converges** although it takes more steps.\n",
    "- With values of x of (10,10) or (-10,-10), the algorithm **does not converge** anymore.\n",
    "\n",
    "In some cases the algorithm fails because the matrix to be inverted is singular. In those cases, a small modification of the initial value usually works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Start using merit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to implementing backtracking gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_backtracking_descent(x_initial, func, grad_func, convergence_criterion=1e-3, print_steps=False):\n",
    "    ''' Find a minimum of funcion \"func\" using backtracking gradient descent '''\n",
    "\n",
    "    # Initial value\n",
    "    x_new = x_initial\n",
    "    F_new = func(x_new)\n",
    "\n",
    "    # Iterate until end condition is met or we reach a maximum of 1000 iterations\n",
    "    for num_iter in range(1000):\n",
    "        x = x_new\n",
    "        F = F_new\n",
    "        \n",
    "        # Compute gradient\n",
    "        dx = grad_func(x)\n",
    "        # Repeat until the gradient size is less than a defined threshold\n",
    "        if (dx[0]**2 + dx[1]**2) < convergence_criterion**2:\n",
    "            print('Convergence reached in {} iterations.'.format(num_iter-1))\n",
    "            print('F={}, x={}'.format(F, x))\n",
    "            break\n",
    "        # Normalize the gradient\n",
    "        dx = dx / np.linalg.norm(dx)\n",
    "\n",
    "        alpha=1\n",
    "        # Inner loop to choose an alpha value, maximum 20 iterations (alpha will be divided by 2**40, approx. 1e12)\n",
    "        for j in range(20):\n",
    "            x_new = x - alpha*dx\n",
    "            F_new = func(x_new)\n",
    "            if print_steps:\n",
    "                print('num_iter={} alpha={} F={}, F_new={}, x_new={}'.format(num_iter, alpha, F, F_new, x_new))\n",
    "            # Repeat until reducing alpha makes F decrease\n",
    "            if F_new<F:\n",
    "                break\n",
    "            alpha = alpha/2\n",
    "        # End of inner loop\n",
    "        \n",
    "    # End of outer loop\n",
    "    \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_penalty_factor=10\n",
    "\n",
    "def func_merit(x):\n",
    "    '''Merit function'''\n",
    "    return func_f(x) + ro_penalty_factor*func_h(x)**2\n",
    "\n",
    "def grad_merit(x):\n",
    "    '''Gradient of the merit function at the given point'''\n",
    "    return grad_f(x) + 2*ro_penalty_factor*func_h(x)*grad_h(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: minimize merit function then apply sequential quadratic method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we minimize the merit function. This will give us a point that is close to the optimum we look for,\n",
    "where we can apply sequential quadratic optimization.\n",
    "\n",
    "When minimizing the merit function, we may use a rather loose convergence criterion, as we do not need much precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence reached in 125 iterations.\n",
      "F=0.1752542897997963, x=[-0.75541607  0.66315565]\n"
     ]
    }
   ],
   "source": [
    "x0 = [10,10]\n",
    "x1 = minimize_backtracking_descent(x0, func_merit, grad_merit, convergence_criterion=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial values: x= [-0.75541607  0.66315565] lambda= 0\n",
      "Convergence reached at step 0\n",
      "Final value: x= [-0.74703827  0.66483595] lambda= -0.2110893558350595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.74703827,  0.66483595]), -0.2110893558350595)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_quadratic(x_initial=x1, lam_initial=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
